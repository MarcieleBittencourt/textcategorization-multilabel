# -*- coding: utf-8 -*- 
import numpy as np
import sklearn as skl
import scipy as scipy


import warnings
warnings.filterwarnings('ignore')

from sklearn import feature_extraction
from sklearn import linear_model
from sklearn import metrics

import sys
sys.path.append('utils')
import helpers as helpers
from helpers import import_dataset_multilabel
import stratified_multilabel_KFold

sys.path.append('src')
from ML_MDLText_alpha import ML_MDLText_alpha as ML_MDLText_alpha
from ML_MDLText import ML_MDLText as ML_MDLText




def main():
    np.random.seed(1)
    """
    Main function
    """ 

    # Check to execution with the sending of dataset to be processed
    datasets = [['medical', 'mulan', 45]]

    # Database name used to identify the experiment in the result file that will be generated by the algorithm    
    # Struct: Database name, type and quantity of labels (the last is mandatory to Mulan database)

    for nomeDataset, tipoDataset, rotulosDataset in datasets:

        # File address where the classification results will be stored.
        pathResults = 'results/' + nomeDataset +'_mean.csv'

        # n_splits: 
        #    Available values: Int
        #	       Number of iterations of cross validation
        n_splits = 5

        # performGrid: 
        #    Available values: True, False
        #	       True: uses grid search (busca em grade) in methods (e.g. SVM, KNN and Random Forest) that are sensitive to variation in parameters.
        #	       False: do not uses grid search in any method 
        performGrid  = True

        # n_splitsGrid: 
        #    Available values: Int
        #	       Number of iterations of cross validation of search and Grid
        n_splitsGrid = 2
    
        # termWeighting: used to defines which terms weight scheme will be used
        #     Available values: 'TFIDF': TFIDF calculated by the function presented in paper "MDLText: An efficient and lightweight text classifier"
        termWeighting = 'TFIDF'
    
        # Function used to import the database. 
        # This function returns the following variables:
        #      dataset: an array of 1 column, where each row corresponds to a message 
        #      classes: an array of classes
        #      target: an array of classes for each message contained in the "dataset" array
        dataset, classes, target = import_dataset_multilabel(nomeDataset, tipoDataset, rotulosDataset, n_splits*n_splitsGrid)

        # list of methods that will be executed:
        methods = ['ML-MDLText_alpha',
                  'ML-MDLText']

        # For each method in the list of methods, executes an experiment with the informed parameters
        for methodName in methods:

            # Print the name of the method that will be executed in this iteration
            print('\n\n\n########################################')
            print('%s' %(methodName)) 
            print('########################################\n')
        
            # Executes an experiment with the current iteration method
            perform_experiment(dataset, target, classes, methodName, nomeDataset, pathResults, performGrid, termWeighting, n_splitsGrid, n_splits)

def perform_experiment(dataset, target, classes, methodName, nomeDataset, pathResults, performGrid, termWeighting, n_splitsGrid, n_splits):
        
    """
    Function used to execute the experiments

    Parameters:
    -----------
    dataset: 
        An array of 1 column, where each line corresponds to a message
    
    target:
        An array with classes of each message contained in "dataset" array

    target:
        An array of dataset classes

    methodName: string
        The name used to identify the method. If necessary, add other methods inside the function return_classifier(). 

    nomeDataset: string
        Database name that will be used to identify the experiment in the results file that will be generated by the algorithm.
        
    pathResults: string
        File address where the classification results will be stored.
        If the specified file does not exists, it will be created. If it exists, the results will be appended to the end of file.
        
    performGrid: boolean
    	       True: uses the grid search in methods (e.g. SVM, KNN and Random Forest) that are sensitive to variation in parameters.
    	       False: does not use grid search in any method  
               
    stopWords: boolean
        True: remove the text stopwords
        False: does not remove the text stopwords

    stemming: boolean
        True: applies stemming to text
        False: does not applies stemming to text
        
    termWeighting: string
        Used to indicate which weight scheme will be used to terms
        Available values: 'TF', 'binary', 'TFIDF_sklearn', 'TFIDF'
              'TF': term frequency 
              'binary': the terms weights will be 0 if the term appears on text or 1 if it does not appears
              'TFIDF_sklearn': TFIDF calculated by a function of scikit learn
              'TFIDF': TFIDF calculated by a function presented on paper "MDLText: An efficient and lightweight text classifier"

    n_splitsGrid: int
        Number of partitions in cross validation of GridSearch

    n_splits: int
        Number of partitions in cross validation of experiment

    """

    # Stratified split of multilabel database
    cv = stratified_multilabel_KFold.stratified_multilabel_KFold(n_splits = n_splits, shuffle = True, randomSeed=1)

    # creates an empty list to store the results obtained in executions
    f1macro = 0
    f1micro = 0
    hammingLoss = 0
    subsetAccuracy = 0


    i=0
    for train_index, test_index in cv.split(target):#lp.transform(target)):

        print('\n\t==============================================')
        print('\tDataset: ' + nomeDataset + ' Method: ' + methodName)
        print('\tK-folds: %d' %(i+1))
        print('\t==============================================')
        
        # Split the Folds
        dataset_train, dataset_test = dataset[train_index], dataset[test_index]
        y_train, y_test = target[train_index], target[test_index]

        # call the function to return a classifier based in the name passed as a parameter value
        classifier = return_classifier(methodName, performGrid, n_splitsGrid)
    
        # Check if it has a timeout for execution of fold, of 2 days
        result = perform_fold(termWeighting, dataset_train, dataset_test, y_train, y_test, classes, classifier, i)

        f1macro += result['F1 macro']
        f1micro += result['F1 micro']
        hammingLoss += result['hammingLoss']
        subsetAccuracy += result['Subset Accuracy']
               
        i+=1
    
    print('Médias')
    print('F1 macro: %1.3f' %(f1macro/n_splits) )
    print('F1 micro: %1.3f' %(f1micro/n_splits) )
    print('hammingLoss: %1.3f' %(hammingLoss/n_splits) )  
    print('Subset Accuracy: %1.3f' %(subsetAccuracy/n_splits) )
    a=1

def perform_fold(termWeighting, dataset_train, dataset_test, y_train, y_test, classes, classifier, i):
        
    """
    Function used to execute each fold

    Parameters:
    -----------
    dataset: 
        An array of 1 column, where each line corresponds to a message 
    """

    if scipy.sparse.issparse(dataset_train):
    
        # train the TF model with training data and converts the training data to and array containing the frequency of terms in each document (TF - term frequency)
        x_train = dataset_train
    
        # convert the test data to an array that contains the frequency of terms in each document (TF - term frequency)
        x_test = dataset_test #converte os dados de teste, usando o modelo gerado pelos dados de treinamento 

    else:
        # initializes the model used to generated the TF representation (term frequency)
        vectorizer = skl.feature_extraction.text.CountVectorizer(analyzer = "word", tokenizer = None, preprocessor = None, stop_words = None, lowercase = True, binary=False, dtype=np.int32 )
    
        # train the TF model with the trainig data and converts the training data to and array that contains the frequency of terms in each document (TF - term frequency)
        x_train = vectorizer.fit_transform(dataset_train) 
    
        # convert the test data to an array that contains the frequency of terms in each document (TF - term frequency)
        x_test = vectorizer.transform(dataset_test) #convert the test data, using a model generated by the training data 


    print('\tAmostras de treinamento: %d' %((x_train.shape[0])))

    # convert TF to TFIDF
    if termWeighting == 'TFIDF':  
        x_train, df_train = helpers.tf2tfidf(x_train, normalize_tf=True, normalize_tfidf=True, return_df=True)
        x_test = helpers.tf2tfidf(x_test, df=df_train, nDocs=x_train.shape[0], normalize_tf=True, normalize_tfidf=True)

     
    # train the classifier with training data
    print('Iniciando Treinamento Fold %i' %(i+1))
    classifier.fit(x_train, y_train)#, classesMeta = np.unique( y_train.sum(axis=1)) ) #x.toarray()
    
    # classifies test data
    print('Iniciando Classificação Fold %i' %(i+1))
    y_pred = classifier.predict(x_test)
    
    # call the function'inf_teste' to calculates and return the classification performance. 
    # This function calculates the accuracy, F-measure, precision and other measures.

    result = {}
    result.update({'F1 macro': skl.metrics.f1_score(y_test, y_pred, average='macro')})
    result.update({'F1 micro': skl.metrics.f1_score(y_test, y_pred, average='micro')})
    result.update({'hammingLoss': skl.metrics.hamming_loss(y_test, y_pred)})
    result.update({'Subset Accuracy': skl.metrics.accuracy_score(y_test, y_pred)})

    print('\nScikit results')
    print('F1 macro: %1.3f' %result['F1 macro'] )
    print('F1 micro: %1.3f' %result['F1 micro'] )
    print('hammingLoss: %1.3f' %result['hammingLoss'] )  
    print('Subset Accuracy: %1.3f' %result['Subset Accuracy'] )

    return result
    
    

def return_classifier(method, performGrid, n_splitsGrid):
    """
    Function used to select a classification method to be used in the experiment
 
    Parameters:
    -----------
    method: string
        A name used to identify the method. If its necessary, add other methods inside the function. 
        
    performGrid: boolean
  	    True: uses a grid search in methods (e.g. SVM, KNN and Random Forest) that are sensitive to variation in parameters.
   	    False: does not uses grid search in any method  

    n_splitsGrid: boolean
  	    int: indicates the k value in cross validation
    """ 
    # Problem transformation methods
    clfClasses = skl.linear_model.SGDClassifier(random_state=5)

    if '_alpha' in method: #MDLText Meta-Classifier version that considers the dependency between classes
        classifier  = ML_MDLText_alpha(clfClasses = clfClasses)

    else: #MDLText Meta-Classifier version that considers the dependency between classes
        classifier  = ML_MDLText(clfClasses = clfClasses, calc_feature_relevance=False)


    return classifier


if __name__ == '__main__':
    
    main() # run the main function
